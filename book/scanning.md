> 大口吃饭。任何值得做的事情都值得玩命去干。
>
> <cite>Robert A. Heinlein, <em>Time Enough for Love</em></cite>

任何编译器或解释器的第一步都是<span name="lexing">scanning</span>(扫描)。扫描器以一系列字符的形式接收原始源代码，并将其分组为一系列我们称之为标识( **tokens** )的块。这些是组成语言语法的有意义的“单词”和“标点”。

<aside name="lexing">

多年来，这项任务被称为扫描 "scanning" 或者词法分析 "lexing" ( "lexical
analysis" 的简称)。很久以前，当计算机像Winnebagos房车一样大，但内存比你的手表还少时，一些人使用“scanner”仅指处理从磁盘读取原始源代码字符并将其缓冲在内存中的那段代码。然后“lexing”是对字符做有用的事情的后续阶段。

如今，将源文件读入内存是很平常的事情，因此它很少在编译器中的单独分一个阶段。因此，这两个术语现在基本上可以互换。

</aside>
扫描对我们来说也是一个很好的起点，因为这段代码并不难--相当于有很多分支的 `switch` 语句。它可以帮助我们在以后处理一些更有趣的材料之前进行热身。在本章结束时，我们将拥有一个全功能的、快速的扫描器，它可以处理任何字符串的Lox源代码并产生标记，我们将在下一章中把这些标记送入解析器中。

## 解释器框架

因为这是我们真正的第一章，在我们开始实际扫描一些代码之前，我们需要勾画出我们的解释器jlox的基本形状。在Java中，一切都是从一个类开始的。

^code lox-class

<aside name="64">

对于退出代码，我使用UNIX中["sysexits.h"][sysexits]标头中定义的约定。这是我能找到的最接近标准的东西。

[sysexits]: https://www.freebsd.org/cgi/man.cgi?query=sysexits&amp;apropos=0&amp;sektion=0&amp;manpath=FreeBSD+4.3-RELEASE&amp;format=html

</aside>

把它贴到一个文本文件中，然后去把你的IDE或者Makefile或者其他工具设置好。我在这里等你准备完毕,准备好了?出发!

Lox是一种脚本语言，这意味着它直接从源代码执行。我们的解释器支持两种运行代码的方式。如果从命令行启动jlox，并给它一个文件路径，它就会读取并执行该文件。

^code run-file

如果您想与解释器进行更亲密的对话，可以交互式的启动它。在没有任何参数的情况下启动jlox，它会有一个提示符，您可以在那里输入和执行代码。

<aside name="repl">

交互式提示符也被称为“REPL”（发音类似于“rebel”，但带有“p”）。这个名字来自Lisp，在Lisp中，实现一个交互式提示符就像围绕几个内置函数包装一个循环一样简单：

```lisp
(print (eval (read)))
```

从最嵌套的调用向外工作，您读取( **R**ead )一行输入，对其求值(**E**valuate)，打印(**P**rint)结果，然后循环(**L**oop)并再次执行。

</aside>

^code prompt

 `readLine()` 函数，顾名思义，从命令行读取用户输入的一行内容，并返回结果。要终止交互式命令行应用程序，通常需要键入 Control-D。这样会向程序发出“文件结束”(EOF)的信号。当发生这种情况时， `readLine()` 返回 `null` ，所以我们检查一下是否存在 null 以退出循环。

交互式提示符和文件运行工具都是对这个核心函数的简单包装：

^code run

由于我们还没有写出解释器，所以这些代码还不是很有用，但不积跬步无以至千里。现在，它可以打印出我们即将完成的扫描器所返回的标记，这样我们就可以看到我们的解析是否生效。

### 错误处理

在我们进行设置时，另一个关键的基础设施是*错误处理*。教科书有时会忽略这一点，因为它更多是一个实践问题而非正式的计算机科学问题。但是，如果你想制作一个真正*可用*的语言，那么优雅地处理错误至关重要。

我们的语言为处理错误所提供的工具构成了其用户界面的很大一部分。当用户的代码在工作时，他们根本不会考虑我们的语言--他们的头脑中全是*他们的程序*。通常只有当程序出现问题时，他们才会注意到我们的实现。

<span name="errors">当</span>这种情况发生时，我们有责任向用户提供他们需要的所有信息，让他们了解哪里出错了，并引导他们慢慢回到他们想去的地方。要做好这一点，意味着从现在开始，在解释器的整个实现过程中都要考虑错误处理。

<aside name="errors">

说了这么多，对于*这个*解释器来说，我们要构建的只是基本框架。我很想谈谈交互式调试器、静态分析器和其它有趣的东西，但是篇幅实在有限。

</aside>

^code lox-error

这个 `error()` 函数和它的工具 `report()` 方法会告诉用户在给定的行中出现了一些语法错误。这是能够声称你*有*错误报告的底线。想象一下，如果您在某个函数调用中不小心留下了一个悬空逗号，解释器会打印出来:

```text
Error: Unexpected "," somewhere in your code. Good luck finding it!
```

这种信息没有多大帮助。我们至少需要把他们指到明确的行。好一些的做法是列出开头和结尾列，这样他们就能知道错误在这一行的位置。更好的是向用户*标识*错误那行的问题，比如：

```text
Error: Unexpected "," in argument list.

    15 | function(first, second,);
                               ^-- Here.
```

我很想在这本书中实现类似的东西，但老实说，这会引入很多繁琐的字符串操作代码。对用户来说非常有用，但在书中读起来并不友好，而且在技术上也比较无聊。所以我们只保留一个行号。在你们自己的解释器中，请照我说的去做，不要照本书的做。

我们把这个错误报告函数放在Lox主类中的主要原因是因为那个 `hadError` 字段。它的定义如下:

^code had-error (1 before)

我们将以此来确保我们不会尝试执行有已知错误的代码。此外，它还能让我们像一个好的命令行工具那样，用一个非零的结束代码退出。

^code exit-code (1 before, 1 after)

我们需要在交互循环中重置此标志。如果用户犯了错误，也不应终止整个会话。

^code reset-had-error (1 before, 1 after)

我把错误报告拉出来，而不是把它塞进扫描器和其他可能发生错误的阶段，还有另一个原因，是为了提醒您，将*产生*错误的代码与*报告*错误的代码分开是一个很好的工程实践。

前端的各个阶段都会检测到错误，但是它们不需要知道如何向用户展示错误。在一个功能齐全的语言实现中，可能会有多种显示错误的方式:在 `stderr` 上，在IDE 的错误窗口中，记录到文件中，等等。您肯定不希望扫描器和解析器中充斥着这类代码。

理想情况下，我们应该有一个实际的抽象，某种<span name="reporter">"ErrorReporter"</span>接口传递给扫描器和解析器，以便我们可以交换不同的报告策略。对于我们这里的简单解释器，我没有这样做，但我至少把错误报告的代码移到了不同的类中。

<aside name="reporter">

在我第一次实现jlox的时候，就是这么干的。我最后把它移除了，因为对于这本书中的最小解释器来说，它感觉设计得过于复杂了。

</aside>

有了一些基本的错误处理，我们的应用程序框架就准备好了。一旦我们有了一个带有 `scanTokens()` 方法的 Scanner 类，我们就可以开始运行它了。在这之前，让我们更精确地了解一下什么是标记。


## 词素和标记（词法单元）

下面是一行Lox代码:

```lox
var language = "lox";
```

这里，`var` 是声明变量( `variable` )的关键字。那个三个字符的序列“v-a-r”是有意义的。但是如果我们从 `language` 中间抽出三个字母，比如“g-u-a”，它们本身没有任何意义。 

这就是词法分析的目的。我们的工作是扫描字符列表，并把它们组合成仍然代表某些东西的最小序列。这些字符块中的每一个都被称为一个 **lexeme** 词素是:

<img src="image/scanning/lexemes.png" alt="'var', 'language', '=', 'lox', ';'" />

词素只是源代码的原始子字符串。然而，在将字符序列分组为词素的过程中，我们偶尔也会发现一些其他有用的信息。当我们获取词素并将其与其他数据捆绑在一起时，结果就是一个标记(token，词法单元)。它包括其他有用的内容，如:

### 标记类型

关键字是语言语法的一部分，所以解析器通常会有这样的代码，“如果下一个 `token` 是 `while` ，那么执行... "。这意味着解析器不仅想知道它有某个标识符的词素 ，还想知道它是否有 *保留* 关键字，以及有 *哪个* 关键字。 

<span name="ugly">解析器</span> 可以通过比较字符串来对原始词素中的标记进行分类，但这很慢，而且有点难看。相反，在我们识别一个词素的时候，我们也会记住它代表 *哪种* 词素 。我们为每个关键词、操作符、标点符号和字面类型都赋予不同的类型。

<aside name="ugly">

毕竟，字符串比较最终要看的是单个字符，而这不正是扫描器的工作吗？

</aside>

^code token-type

### 字面值

有用于字面值的词素，例如数字和字符串之类的。由于扫描器必须遍历文本中的每个字符以正确识别它，因此它还可以将该文本表示的值转换为解释器以后使用的活的运行时对象。

### 位置信息

早在我宣讲错误处理的福音时，我们就看到，我们需要告诉用户错误发生的位置。用户从这里开始定位问题。在我们的简易解释器中，我们只标记出在哪一行，但更复杂的实现也包括列和长度。

<aside name="location">

一些标记实现将位置存储为两个数字：从源文件的起始位置到词素起始位置的偏移量，以及词素的长度。扫描器无论如何都会知道这些数字，因此计算这些数字没有任何开销。

偏移量可以通过回看源文件和计算前面的换行来转换为行和列的位置。这听起来很慢，而且确实如此。然而，*只有当你需要向用户实际显示行和列的时候* ，你才需要这样做。大多数标记不会出现在错误信息中。对于这种情况，提前计算位置信息的时间越少越好。

</aside>

我们将所有这些数据打包到一个类中。

^code token-class

现在我们有了一个足以支撑解释器的所有后期阶段的手脚架。

## 正则语言和表达式

现在我们知道了我们要输出什么，让我们开工吧。扫描器的核心是一个循环。从源代码的第一个字符开始，扫描器找出该字符属于哪个词素，并消费它和属于该词素的任何后续字符。当到达该词素的末尾时，扫描器会输出一个标记（词法单元 token）。

然后再循环一次，从源代码中的下一个字符开始，再重复一遍。它一直这样做，吃掉字符，偶尔，呃，排泄出标记 ，直到它到达输入的结尾。

<span name="alligator"></span>

<img src="image/scanning/lexigator.png" alt="An alligator eating characters and, well, you don't want to know." />

<aside name="alligator">

词法分析器.

</aside>

在循环中，我们会查看一些字符，以确定它“匹配”哪种词素 ，这听起来可能很熟悉。如果您知道正则表达式，您可能会考虑为每种词素定义一个正则表达式，并使用它们来匹配字符。例如，对于标识符(变量名之类的)，Lox和C有相同的规则。可以用以下正则表达式匹配:

```text
[a-zA-Z_][a-zA-Z_0-9]*
```

如果你确实想到了正则表达式，你的直觉很准。决定一种特定语言如何将字符分组为 词素的规则被称为其 <span name="theory">**lexical grammar** 词法语法</span>。在Lox中，和大多数编程语言一样，该语法的规则简单到足以使该语言被归为 **[regular language][]** （正则语言）。这里的正则与正则表达式中的 "正则" 意思是一样的。

[regular language]: https://en.wikipedia.org/wiki/Regular_language

<aside name="theory">

我很痛心如此掩盖理论，尤其是当它像我认为的[Chomsky hierarchy][]（乔姆斯基层次结构）和[finite-state machines][]（有限状态自动机）那样有趣时。但老实说，其他书比我讲得更好。《编译原理 技术与工具》（[*Compilers: Principles, Techniques, and Tools*][dragon] 普遍被称为 "龙书"）是本经典的参考书。

[chomsky hierarchy]: https://en.wikipedia.org/wiki/Chomsky_hierarchy
[dragon]: https://en.wikipedia.org/wiki/Compilers:_Principles,_Techniques,_and_Tools
[finite-state machines]: https://en.wikipedia.org/wiki/Finite-state_machine

</aside>

如果你想的话，你 *可以* 使用正则表达式非常精确地识别 Lox 的所有不同的词素 ，这背后有一堆有趣的理论，解释了为什么会这样，它意味着什么。像[Lex][]或[Flex][]这样的工具就是为了让你做到这一点而设计的——向它们扔几个正则表达式，它们就会<span name="lex">给</span>你一个完整的扫描器。

<aside name="lex">

Lex是由Mike Lesk和Eric Schmidt创建的。是的，就是那个担任谷歌执行主席的Eric Schmidt。我并不是说编程语言是通往财富和名声的必经之路，但我们中*至少*有一个巨型亿万富翁。

</aside>

[lex]: http://dinosaur.compilertools.net/lex/
[flex]: https://github.com/westes/flex

因为我们的目标是了解扫描器是如何工作的，所以我们不会使用这类工具的。我们要亲自动手实现。

## 扫描类

事不宜迟，我们自己做个扫描器吧。

^code scanner-class

<aside name="static-import">

我知道静态导入被一些人认为是不好的风格，但它们使我不必在扫描器和分析器上到处撒下 `TokenType.` . 请原谅我，但书中的每个字符都很重要。

</aside>

我们将原始的源代码存储为一个简单的字符串，并且我们已经准备了一个列表来保存扫描时产生的标记。前面提到的循环看起来类似于：

^code scan-tokens


扫描器遍历源代码，添加标记 ，直到遍历完所有字符。然后，它追加一个最终的“文件结束”（EOF） 标记 。这并不是严格需要的，但它使我们的解析器更清晰。 

这个循环依赖于几个成员变量来跟踪扫描器在源代码中的位置。

^code scan-state (1 before, 2 after)

`start` 和 `current` 记录字符串中的偏移量。 `start` 指向被扫描词素中的第一个字符， `current` 指向当前正在处理的字符。 `line` 跟踪当前所处的行，这样我们产生的标记就可以知道其位置。

然后我们有一个小小的辅助函数，用来告诉我们是否已消费完所有字符。

^code is-at-end

## 识别词素

在每一轮循环中，我们扫描出一个标记。这是扫描器的真正核心。我们从简单的开始。想象一下，如果每个词素只有一个字符长。您所需要做的就是消费下一个字符，并为它选择一个标记类型。有几个词素在Lox中*只包含*单个字符，就从这些开始吧。

^code scan-token

<aside name="slash">

想知道为什么 `/` 没有在这里？别担心，我们会说到它的。

</aside>

同样，我们需要几个辅助函数。

^code advance-and-add-token

 `advance()` 方法获取源文件中的下一个字符并返回它。`advance()` 用于处理输入， `addToken()` 则用于输出，它获取当前词素的文本，并为其创建一个新的标记 。我们将很快使用另一个重载来处理带有字面值的标记 。

### 词法错误

在我们深入探讨之前，让我们花点时间考虑一下词法层面上的错误。如果用户向我们的解释器输入一个包含 Lox 不使用的字符的源文件，如 `@#^` ，会发生什么？现在，这些字符被默默地丢弃了。 Lox 语言不使用这些字符，但这并不意味着解释器可以假装它们不存在。相反，我们应该报告一个错误。

^code char-error (1 before, 1 after)

请注意，错误的字符仍然被被前面调用的 `advance()` 所消耗。这一点很重要，这样我们才不会陷入无限循环。 

还要注意，我们<span name="shotgun">*一直在扫描*</span>。程序后面可能还有其他错误。如果我们一次检测尽可能多的内容，会给我们的用户带来更好的体验。否则，他们看到一个小错误并修复它，结果却出现下一个错误，如此往复。打地鼠般的修改语法错误一点也不好玩。 

(不用担心。由于 `hadError` 已经被设置，我们将永远不会尝试执行任何代码，即使我们继续前进并扫描其余部分。)

<aside name="shotgun">

代码分别报告每个无效字符，所以如果用户不小心粘贴了一大堆奇怪的文字，就会出现大量错误。将所有无效字符凝聚成一个错误会给用户带来更好的体验。

</aside>

### 操作符

单字符词素已经可以正常工作了，但这并不涵盖 Lox 的所有操作符。那么 `!` 呢？它是一个单字符，对吗？有时候是的，但是如果下一个字符是一个等号，那么我们应该创建一个 `!=` 词素 。注意 `!` 和 `=` 不是两个独立的运算符。你不能在 Lox 中写成 `!   =` ，来表示不等操作符。这就是为什么我们需要将 `!=` 作为一个词素来扫描。同样，`<` ,  `>` , 和 `=` 都可以在后面加上 `=` 来创建其他相等和比较运算符。

对于所有这些，我们需要看看第二个字符。

^code two-char-tokens (1 before, 2 after)

这种情况,我们可以用以下新函数处理:

^code match

这就像一个带条件的 `advance()` 。只有当前字符是我们正在寻找的字符时，才消耗当前的字符。
，                             
使用 `match()` ，我们分两个阶段识别这些词素 。例如，当我们到达 `!` 时，我们跳到它的 `switch case` 。这意味着我们知道这个词素是以 `!` 开始的。然后，我们看下一个字符，以确定我们是在处理 `!=` 还是 `!` 。

## 更长的词素

我们仍然漏了一个操作符:  `/` ，除法。该字符需要一些特殊处理，因为注释也以斜杠开头。

^code slash (1 before, 2 after)

这与其他双字符的运算符类似，区别在于当我们找到第二个 `/` 时，还没有结束本次标记。相反，我们继续消耗字符，直至行尾。

这是我们处理较长词素的一般策略。当我们检测到一个词素的开头时，我们会分流到一些特定于该词素的代码，这些代码会不断地消耗字符，直到结尾。

我们还需要另一个辅助函数：

^code peek

它有点像 `advance()` ，但不消耗字符。这就是所谓的<span name="match">**lookahead**</span>（前瞻）。因为它只关注当前未消耗的字符，所以我们有*一个字符的前瞻*。一般来说，前瞻的字符越少，扫描器的运行速度就越快。词法语法的规则决定了我们需要前瞻多少字符。幸运的是，大多数被广泛使用的语言只需要前瞻一到两个字符。

<aside name="match">

从技术上讲， `match()` 也是在做前瞻。  `advance()` 和 `peek()` 是基本运算符，而 `match()` 则是将它们结合起来。

</aside>

注释是词素，但它们没有意义，解析器也不想处理它们。因此，到达注释的末尾时，我们*不*调用 `addToken()` 。当我们回过头来开始下一个词素时，`start` 被重置，注释的词素烟消云散。

既然如此，现在是跳过那些其他无意义的字符的好时机：换行和空白。

^code whitespace (1 before, 3 after)


当遇到空白字符时，我们只需回到扫描循环的起点。这样就会在空白字符之后开始一个新的词素。对于换行，我们同样如此处理，但我们也累加行计数器。(这就是为什么我们用 `peek()` 来寻找结束注释的换行符，而不是用 `match()` 。我们希望能读到那个换行符，这样我们就可以更新 `line` 行数了） 。

我们的扫描器越来越智能了。它可以处理相当自由的代码，如：

```lox
// this is a comment
(( )){} // grouping stuff
!*+-/=<> <= == // operators
```

### 字符串字面值

我们对长词素已经很熟悉了，现在可以开始处理字面量了。我们将首先处理字符串，因为它们总是以特定字符开头，`"` 。

^code string-start (1 before, 2 after)

这里将调用：

^code string

与注释类似，我们消耗字符，直到我们碰到结束字符串的 `"` 。我们也会优雅地处理在字符串关闭前输入完毕的情况，并为此报告一个错误。

Lox支持多行字符串，这没啥特殊原因。支持跨行有利有弊，但禁止跨行比允许换行要复杂一点，所以我把它们保留了下来。这意味着当我们在字符串中遇到换行符时，我们也需要更新  `line` 值。

最后，还有一点很有趣，当我们创建标记时，我们也会生成实际的字符串*值*，解释器稍后将使用该值。在这里，值的转换只需要一个 `substring()` 来剥离前后的引号。如果 Lox 支持像  `\n` 这样的转义序列，我们将在这里取消转义。

### 数字字面值

Lox中的所有数字在运行时都是浮点型的，但是支持整数和小数字面值。数字字面值是一系列<span name="minus">数字</span>，可选地后跟一个 `.` 和一个或多个尾随数字。

<aside name="minus">

由于我们只寻找一个数字作为开始，这意味着 `-123` 不是一个数字字面值。相反，`-123` 是一个*表达式*，`-` 应用于数字字面值 `123` 。在实践中，结果是一样的，尽管它有一个有趣的边缘情况，如果我们要在数字上增加方法调用的话。请考虑一下:

```lox
print -123.abs();
```

这将打印出 `-123` ，因为取负值的优先级比方法调用低。我们可以通过使 `-` 成为数字字面值的一部分来解决这个问题。但是，再考虑一下:

```lox
var n = 123;
print -n.abs();
```

这仍然会产生 `-123` ，所以现在的语言似乎不一致了。不管你怎么做，有些情况最终会变得很奇怪。

</aside>

```lox
1234
12.34
```

我们不允许前导或尾随小数点，因此以下写法都是无效的：

```lox
.1234
1234.
```

我们可以很容易地支持前者，但为了保持简单，我把它排除在外。如果我们想允许`123.sqrt()` 这样的数字方法调用，后者就会变得很奇怪。

为了识别一个数字词素的开头，我们寻找任何数字。每个十进制数字添加 case 分支有点无聊，所以我们直接在默认分支中进行处理。

^code digit-start (1 before, 1 after)

这依赖于这个小工具函数:

^code is-digit

<aside name="is-digit">

Java标准库提供了[`Character.isDigit()`][is-digit]，这似乎很合适。然而，该方法允许像梵文数字、全宽数字和其他我们不想要的有趣东西。

[is-digit]: http://docs.oracle.com/javase/7/docs/api/java/lang/Character.html#isDigit(char)

</aside>

一旦我们知道当前在处理数字，我们就分支进入一个单独的方法消费剩余的字面量，跟字符串的处理类似。

^code number

我们在字面值的整数部分尽可能多地获取数字。然后我们寻找小数部分，也就是小数点 (`.`) 后面至少有一个数字。如果我们确实有小数部分，同样，我们要尽可能多地消耗我们能找到的数字。

在定位到小数点之后需要继续前瞻第二个字符，因为我们只有确认其*后*有数字才会处理 `.` 。所以我们添加了:

^code peek-next

<aside name="peek-next">

我本可以让 `peek()` 接受一个参数来决定要看多少个字符，而不是定义两个函数，但这将允许前瞻任意长度的字符。提供这两个函数可以使代码的读者更清楚地了解到我们的扫描器最多只能前瞻两个字符。

</aside>

最后，我们将词素转换为其对应的数值。我们的解释器使用 Java 的 `Double` 类型来表示数字，所以我们制造了一个该类型的值。我们使用 Java 自带的解析方法将词素转换为真正的 Java double 类型。我们可以自己实现这一点，但是，说实话，除非你想为即将到来的技术面试做准备，否则不值得在这上面花时间。

剩下的字面值是布尔值和  `nil` ，但是我们将把它们当作关键字来处理，这样我们就可以......

## 保留字和标识符

我们的扫描器就要完成了。词法语法中还剩下要实现的部分只有标识符和他们的表亲，保留字。您可能认为我们可以用处理多字符操作符（如 `<=` ）的方法来匹配 `or`  等关键字。

```java
case 'o':
  if (match('r')) {
    addToken(OR);
  }
  break;
```

考虑一下如果用户将变量命名为 `orchid` 会发生什么。扫描器将看到前两个字母  `or` ，然后立刻生成一个 `or` 关键字标记。这就引出了一个重要的原则，叫做<span name="maximal">**maximal munch**（贪婪匹配）</span>。当两个词法规则都能匹配扫描器正在查看的代码块时，匹配字符最多的规则获胜。

That rule states that if we can match `orchid` as an identifier and `or` as a
keyword, then the former wins. This is also why we tacitly assumed, previously,
that `<=` should be scanned as a single `<=` token and not `<` followed by `=`.

该规则规定，如果我们可以匹配 `orchid` 作为标识符，也可以匹配 `or` 作为关键字，则前者获胜。这也是为什么我们先前默认地假设 `<=` 应该作为单个 `<=` 标记而不是 `<` 后面跟着 `=` 来扫描。


<aside name="maximal">

看看这段令人生厌的c代码:

```c
---a;
```

它有效么？这取决于扫描器如何分割词素，如果扫描器这么拆分：

```c
- --a;
```

这样可以解析。但这需要扫描器了解代码前后的语法结构，这会使事情变得比我们想要的更复杂。相反，贪婪匹配规则总是扫描成：


```c
-- -a;
```

它就会这样扫描，尽管这样做会在解析器中会导致后面的语法错误。

</aside>

贪婪匹配意味着直到我们到达了一个标识符的末尾，我们才能确定是否检测到一个保留字。毕竟，保留字也是一个标识符，它只是一个被语言声明为内部使用的标识符。这就是 **reserved word** 保留字这个词的由来。

因此，我们开始假设任何以字母或下划线开头的词素都是标识符。

^code identifier-start (3 before, 3 after)

代码的其余部分位于此处：

^code identifier

我们用这些辅助函数：

^code is-alpha

这样标识符就开始工作了。为了处理关键字，我们查看标识符的词素是否是保留字之一。如果是，我们使用特定于该关键字的标记类型。我们在 map 中定义了保留字集合。

^code keyword-map

接下来，在我们扫描到标识符之后，需要检查它是否与 map 中的任何内容匹配。

^code keyword-type (2 before, 1 after)

如果匹配,我们就是用该关键字的标记类型。否则，他就是一个普通的用户定义的标识符。

至此，我们现在有了一个完整的Lox词法扫描器。启动 REPL ，输入一些有效和无效的代码。它是否产生您期望的标记？试着想出一些有趣的边界情况，看看它是否能够正确处理它们。

<div class="challenges">

## Challenges

1.  Python 和 Haskell 的词法是非 *正则* 的。这是什么意思，为什么它们不是呢？

    Python和Haskell都采用了对缩进敏感的语法，所以它们必须将缩进级别的变动识别为词法标记。这样做需要比较连续行的开头空格数量，这是使用正则语法无法做到的。

1.  除了分隔标记 例如:--区分 `print foo` 和 `printfoo` -- 空格在大多数语言中没有什么用处。然而，在一些隐秘的角落里，空格 *确实* 影响了 CoffeeScript 、Ruby和C语言预处理器对代码的解析。在这些语言中，它在哪里以及有什么影响呢？

1.  我们这里的扫描器和大多数扫描器一样，抛弃了注释和空白，因为解析器不需要这些东西。什么时候你会想写一个*不*丢弃这些东西的扫描器？它有什么用处？

1.  为 Lox 的扫描器增加对 C 风格  `/* ... */`  块注释的支持。确保能处理其中的换行符。考虑允许它们嵌套。增加对嵌套的支持的工作量是否比你预期的要多？为什么？

</div>

<div class="design-note">

## Design Note: 隐式分号

现在的程序员已经被越来越多的语言选择宠坏了，对语法也变得挑剔起来。他们希望自己的语言看起来干净、现代化。几乎每一种新语言都会放弃这个小的语法点（有些古老的语言如BASIC从来没有过），那就是 `;` 作为一个显式的语句终止符。

相对地，它们将“有意义的”换行符看作是语句结束符。"有意义的地方 "这部分是具有挑战性的。尽管*大多数的*语句都是在同一行，但有时你需要将一条语句扩展到多行。这些混杂的换行符不应该被当作终止符来处理。

大多数明显应该忽略换行的情况都很容易发现，但也有一些讨厌的情况。

* 返回值在下一行中:

    ```js
    if (condition) return
    "value"
    ```

    "value" 是被返回的值，还是我们有一个空 `return` 语句，后面是一个包含字符串字面值的表达式语句？

* 下一行中有带圆括号的表达式:

    ```js
    func
    (parenthesized)
    ```

    这是一个对  `func(parenthesized)` 函数的调用,还是两个表达式语句,一个是 `func` ,另一个是圆括号表达式?

* A `-` 在新行中:

    ```js
    first
    -second
    ```

    这 `first - second` 是中缀减法还是两个表达式语句，一个 `first`，另一个 `-second`？

在所有这些案例中，无论是否将换行符作为分隔符都会产生有效的代码，但可能不是用户想要的代码。在不同的语言中，有各种令人不安的规则用来决定哪些换行符是分隔符。下面是几个例子。

*   [Lua][] 完全无视换行符，但是仔细地控制了它的语法，在大多数情况下，语句之间根本就不需要分隔符。这完全是合法的:

    ```lua
    a = 1 b = 2
    ```

    Lua通过要求 `return` 语句是一个块中的最后一个语句来避免 `return` 问题。如果在关键字 `end` 之前的 `return` 后面有一个值，它必须是用于`return` 的。对于其他两种情况，他们允许使用显式的 `;` ，并期望用户使用它。在实践中，这几乎从未发生过，因为括号或一元否定表达式语句的语句没有任何意义。


*   [Go][] 在扫描器中处理换行。如果换行出现在已知可能结束语句的少数标记类型之后，换行会被当作分号处理。否则，它将被忽略。Go团队提供了一个规范的代码格式化器，[gofmt][] ，而且生态系统热衷于使用它，这确保了常用样式的代码能够很好地遵循这个简单的规则。


*   [Python][] 将所有的换行线都视为有效，除非在行末使用明确的反斜杠将其延续到下一行。然而，在一对大括号 (`()`, `[]`、或 `{}`) 内的任何地方的换行线都被忽略。惯用风格更倾向于后者。

    这个规则对 Python 很适用，因为它是一种高度面向语句的语言。特别是， Python 的语法确保语句不会出现在表达式中。 C 也是这样做的，但许多其他具有“lambda”或函数字面量语法的语言则不然。

    举一个 JavaScript 中的例子：

    ```js
    console.log(function() {
      statement();
    });
    ```

    此处，`console.log()` *表达式* 包含一个函数字面量，该函数字面量又包含 *语句* `statement();` 。

    如果一个<span name="lambda">语句</span>中，换行符应该变得有意义，同时仍然嵌套在括号内，那么 Python 将需要一套不同的隐式连接行的规则。

<aside name="lambda">

现在你知道为什么Python的 `lambda` 只允许一个表达式体了吧。

</aside>

*   JavaScript 的 "自动插入分号 "规则("[automatic semicolon insertion][asi]")才是真正的奇葩。其他语言认为大多数换行符都是有意义的，在多行语句中只有少数换行符应该被忽略，而JS的假设恰恰相反。它把所有的换行符都视为无意义的空白，除非它遇到了一个解析错误。如果遇到了，它就会回去尝试把前一个换行符变成分号，以获得语法上有效的东西。

    如果我对这个问题的工作原理进行详细的说明，那么这篇设计说明就会变成一篇设计檄文了，更不用说JavaScript的 "解决方案 "是各种坏主意的集合了。这是个混乱的问题。JavaScript是我所知道的唯一一种这样做的语言，它的许多风格指南都要求在每个语句后面都有明确的分号，尽管这种语言理论上允许你省略它们。

如果你正在设计一种新的语言，则几乎肯定应该避免使用显式的语句终止符。程序员和其他人类一样都是时尚的创造者，分号就像所有关键字必须大写（ALL CAPS KEYWORDS）一样已经过时了。只是要确保您选择了一套适用于您语言的特定语法和习语的规则即可，而不要重蹈 JavaScript 的覆辙。


</div>

[lua]: https://www.lua.org/pil/1.1.html
[go]: https://golang.org/ref/spec#Semicolons
[gofmt]: https://golang.org/cmd/gofmt/
[python]: https://docs.python.org/3.5/reference/lexical_analysis.html#implicit-line-joining
[asi]: https://www.ecma-international.org/ecma-262/5.1/#sec-7.9
